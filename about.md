---
layout: page
title: About
---

<!-- <p class="message">
  Hey there! This page is included as an example. Feel free to customize it for your own use upon downloading. Carry on!
</p> -->

Hello! I'm Krishna Agaram, a final-year CS undergrad at IIT Bombay. I enjoy theoretical CS, quantum computing, pure math, reinforcement learning, and the occasional dev project. I've worked and am working on reinforcement learning, property testing, probabilistic proofs and quantum information. Pure math gets me excited every time. Currently interested in combinatorics with an algebraic flavor.

If I'm not working some math, I'm likely reading Asimov or Christie, playing the piano, or am outdoors on a run or bike, climb or hike. I'm always looking to learn new things and meet new people, so feel free to connect if any of the above topics interest you too (or even if not)!

My [CV](https://mathismusic.github.io/krishna-agaram-cv-dec8.pdf) and [Github](https://github.com/mathismusic).

<!-- P.S. this website is a stub and is mostly a placeholder for now. A few old blog entries on the home page, that's all. More to come soon! -->

I sometimes make notes, which you can find [here](https://github.com/mathismusic/notes). I am a big supporter of [inquiry-based learning](https://en.wikipedia.org/wiki/Inquiry-based_learning); if you're interested, I encourage checking out [JIBLM](https://jiblm.org/guides/index.php?category=jiblmjournal). I have authored one such guide to [Linear Algebra](https://mathismusic.github.io/ibl-linear-alg.pdf) and a more elementary, story-book guide to [Counting](https://mathismusic.github.io/story-draft.pdf) (draft). Finally, I have a [dead blog](https://mathismusic.github.io/website2024) that needs revival.

### Coursework

- **undergraduate CS theory**: data structures, algorithm analysis, logic, automata theory, cryptography, game theory and mechanism design
- **graduate CS theory**: quantum information, spectral graph theory, approximation algorithms, randomized algorithms, theoretical machine learning, formal methods in machine learning
- **math**: linear algebra, differential equations, calculus 1&2, analysis, abstract algebra, probability and statistics, numerical analysis, extremal graph theory and graph regularity (graduate)
- **undergraduate systems**: software systems, architecture, networks, operating systems, databases, compilers

<!-- Additionally, I read up things that take my fancy: so far, complex analysis, analytic combinatorics, quantum algorithms and error correction, probabilistic proofs -->



### Misc

Some  remarks (which certainly shouldn't be on the main page, I apologize)

- One of my all-time favorite topics is [Analytic Combinatorics](https://ac.cs.princeton.edu/home/AC.pdf), an area that marries combinatorics to algebra and complex analysis. It's a beautiful book, built upon the composition of seemingly elementary operations applied to classes of combinatorial objects to build new ones, and I highly recommend it to anyone interested in generating functions. My dream is to one day have an opportunity to use it in CS theory research.
- Recently, after a course on theoretical machine learning, I have been giving some vague thought to a complexity-theoretic analysis of machine learning approaches: is it possible to have a complexity theory of deep learning, with problems falling into different (parameterized by size, surely) complexity classes corresponding to (say) different architectures? Essentially, if we think of machine learning as a new paradigm of computing, then this is simply its complexity theory. I'm not sure if this is a well-defined question, but it's interesting to think about.